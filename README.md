## ğŸ’¡ Motivation

While working on deep learning projects, I realized that **environment setup** is often the most frustrating and time-consuming part.  
To streamline this process, I built a ready-to-use **Docker environment** based on **Ubuntu 22.04** with **CUDA 11.8** support. This setup allows you to skip the hassle of **dependency conflicts** and focus directly on **model development and experimentation**. ğŸ˜

---

## ğŸš€ Features

- âœ… One-command Docker setup with optional dataset mounting  
- âœ… Automatic image build if not found  
- âœ… Easy volume linking using `___DATASETS___.list`  
- âœ… Automatically links `requirements.txt` into container  
- âœ… CUDA 11.8 + Ubuntu 22.04 base for maximum compatibility  

---


## ğŸ› ï¸ Usage


### 1. Add your dataset path  

If you already have datasets stored on your machine, just write their paths in `___DATASETS___.list`
Edit the `___DATASETS___.list` file to include the absolute paths to your datasets(e.g., coco, VOC...), one per line.  

```cmd
___DATASETS___.list
/home/yourname/datasets/my_coco_dataset
/mnt/data/datasets/balloon_dataset
/mnt/data2/VOC_dataset
```

Each will be mounted inside the container under:

```container
/workspace/DATASETS/<dataset_name>
```




### 2. Run the container  

```cmd
bash run.sh -v /path/to/your_project_dir
```

The `-v` option specifies the **host directory** to be mounted as the containerâ€™s working directory (`/workspace`).  
This is where your code and project files will be accessible inside the container.  

> ğŸ’¡ If you omit the `-v` option, your **current working directory** will be mounted by default.




### 3. Access the container  

Once the container is running, you can enter it using:

```bash
docker exec -it ubuntu22.04_cuda11.08_container bash
```

<details>
<summary><strong>ğŸ“¦ Container Structure (click to expand)</strong></summary>

```text
ğŸ“ /  # root
â””â”€â”€ ğŸ“ workspace
    â”œâ”€â”€ ğŸ“ DATASETS
    â”‚   â”œâ”€â”€ ğŸ“ coco_example
    â”‚   â””â”€â”€ ğŸ“ <another_dataset>
    â”‚
    â”œâ”€â”€ ğŸ“ <your_project_dir>   # e.g., Ultralytics, mmdetection
    â””â”€â”€ ğŸ“„ requirements.txt     # symlinked automatically
```

</details>


- `/workspace` â†’ your working directory  
- `/workspace/DATASETS/<dataset_name>` â†’ dataset mounted via `___DATASETS___.list`  


### 4. Install pip dependencies
After entering the container, install Python dependencies using:
```container
pip install -r requirements.txt
```
This will install all the packages listed in your project's `requirements.txt`
<details>
<summary><strong>ğŸ“¦ Python Dependencies (Click to expand)</strong></summary>


<details>
```text
# Use the PyTorch CUDA 11.8 wheel repository 
--extra-index-url https://download.pytorch.org/whl/cu118

# Core DL packages with CUDA 11.8
torch==2.1.0+cu118  
torchvision==0.16.0+cu118  
torchaudio==2.1.0  

# General dependencies
numpy==1.22.3  
pillow==8.2.0  
requests==2.32.3  
certifi==2024.8.30  
urllib3==2.2.3  
idna==3.10  
charset-normalizer==3.4.0  
typing_extensions==4.12.2  
pyyaml==6.0  
filelock==3.16.1  
jinja2==3.1.4  
sympy==1.13.3  
networkx==3.1  
cffi==1.15.0  
pycparser==2.22  
pysocks==1.7.1  
markupsafe==2.1.1  
olefile==0.47  
```
</details>

### 5. Enjoy your deep learning development env! ğŸ˜
